{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Reshape\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGENET_MEANS = [0.40760392, 0.45795686, 0.48501961]\n",
    "# IMAGENET_MEANS = [103.939, 116.779, 123.68]\n",
    "\n",
    "def process_image(img):\n",
    "    processed_image = np.array(img).astype(np.float32)\n",
    "    processed_image /= 255\n",
    "    for x in range(3):\n",
    "        processed_image[:, :, x] -= IMAGENET_MEANS[x]\n",
    "    return processed_image\n",
    "        \n",
    "def restore_image(img):\n",
    "    restored_image = np.array(img)\n",
    "    for x in range(3):\n",
    "        restored_image[:, :, x] += IMAGENET_MEANS[x]\n",
    "    restored_image.clip(0, 1)\n",
    "    restored_image *= 255\n",
    "    return restored_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"../../data/images/Amsterdam.jpg\", 1)\n",
    "img = cv2.resize(img, (224, 224))\n",
    "\n",
    "processed_img = process_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img[:, :, [2, 1, 0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = keras.applications.vgg16.VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None)\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_pos_dict = {\"conv1_2\" : 2, \"conv2_2\" : 5, \"conv3_2\" : 8, \"conv4_2\" : 12, \"conv5_2\" : 16}\n",
    "layer_pick = \"conv3_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_target_layer = K.function([vgg16.layers[0].input],\n",
    "                              [vgg16.layers[layer_pos_dict[layer_pick]].output])\n",
    "img_input = np.expand_dims(processed_img, axis=0)\n",
    "target_layer = get_target_layer([img_input])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_proxy = Input(shape=(1,))\n",
    "image_pixels = Dense(224 * 224 * 3, use_bias=False)(input_proxy)\n",
    "input_image = Reshape((224, 224, 3))(image_pixels)\n",
    "last_layer = input_image\n",
    "for i in range(1, layer_pos_dict[layer_pick] + 1):\n",
    "    next_layer = vgg16.layers[i](last_layer)\n",
    "    last_layer = next_layer\n",
    "    \n",
    "structure_rebound_model = Model(inputs=input_proxy, outputs=last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_rebound_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structure_rebound_model.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_rebound_model.fit(np.ones((1,)), [target_layer], epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recover_image = K.function([structure_rebound_model.layers[0].input],\n",
    "                           [structure_rebound_model.layers[2].output])\n",
    "output_image = recover_image([np.ones((1,1))])[0][0, :, :, :]\n",
    "restored_image = restore_image(output_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(restored_image[:, :, [2, 1, 0]])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(img[:, :, [2, 1, 0]])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:dl_env]",
   "language": "python",
   "name": "conda-env-dl_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
