{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook defines and tests the implementation of the WaveNet model:\n",
    "\n",
    "The original paper is here: https://arxiv.org/pdf/1609.03499.pdf\n",
    "\n",
    "Some additional reference for code: https://github.com/ibab/tensorflow-wavenet/blob/master/wavenet/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "from IPython.display import Audio\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the music track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_track, sample_rate = librosa.load(\"../../data/music/kalpol_introl.mp3\", mono=True, sr=220)\n",
    "Audio(data=music_track, rate=sample_rate, autoplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(music_track)), music_track)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WaveNet model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As outined in the paper, the model takes non-linear qunatization of input waveform as input and predict it for the next signal.\n",
    "\n",
    "The exact implemntation was taken from the github link above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mu_law_encode(audio, quantization_channels=256):\n",
    "    mu = float(quantization_channels) - 1\n",
    "    # Perform mu-law companding transformation (ITU-T, 1988).\n",
    "    # Minimum operation is here to deal with rare large amplitudes caused by resampling.\n",
    "    safe_audio_abs = np.minimum(np.abs(audio), 1.0)\n",
    "    magnitude = np.log1p(mu * safe_audio_abs) / np.log1p(mu)\n",
    "    signal = np.sign(audio) * magnitude\n",
    "    # Quantize signal to the specified number of levels.\n",
    "    return ((signal + 1) / 2 * mu + 0.5).astype(int)\n",
    "\n",
    "def mu_law_decode(output, quantization_channels=256):\n",
    "    mu = quantization_channels - 1\n",
    "    # Map values back to [-1, 1].\n",
    "    signal = 2 * (output.astype(float) / mu) - 1\n",
    "    # Perform inverse of mu-law transformation.\n",
    "    magnitude = (1 / mu) * ((1 + mu)**abs(signal) - 1)\n",
    "    return np.sign(signal) * magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WaveNet:\n",
    "    \n",
    "    def __init__(self, model_name, n_dilation_blocks, max_dilation_base,\n",
    "                 n_dilation_filters, n_residual_channels=1, learning_rate=0.1):\n",
    "        with tf.variable_scope(model_name):\n",
    "            self.model_name = model_name\n",
    "            self.n_dilation_blocks = n_dilation_blocks\n",
    "            self.max_dilation_base = max_dilation_base\n",
    "            self.n_dilation_filters = n_dilation_filters\n",
    "            self.n_residual_channels = n_residual_channels\n",
    "            self.learning_rate = 0.1\n",
    "            self.session = tf.Session()\n",
    "\n",
    "            # The model / prediction is assumed to start with quantizied signals\n",
    "            # That way they are categorigal variables and have to be mapped back to continious form\n",
    "            # The embedding dimension depends on the number of resudual channels flowing through the model\n",
    "            self.input_layer = tf.placeholder(shape=(1, None), dtype=tf.int32)\n",
    "            self.embeddings = tf.Variable(tf.random_uniform([256, n_residual_channels], -1, 1), name=\"embeddings\")\n",
    "            self.embedded_input = tf.nn.embedding_lookup(self.embeddings, self.input_layer)\n",
    "            \n",
    "            # Setting the flow of residuals - will be additively accumulated through the network\n",
    "            residual_flow = self.embedded_input\n",
    "\n",
    "            # Setting skip_connection_layer - it is going to accumulate all outputs of intermediary layers\n",
    "            # For the future: this has to point for current state of residual_flow if I go for N_RESIDUAL_CHANNELS > 1\n",
    "            skip_connections_layer = self.embedded_input\n",
    "\n",
    "            # Going through stacks of dilated convolution layers\n",
    "            dilation_steps = [2 ** i for i in range(max_dilation_base)]\n",
    "            for block_num in range(1, n_dilation_blocks + 1):\n",
    "                for d in dilation_steps:\n",
    "\n",
    "                    # Padding the intermediary sequences / layers from left\n",
    "                    paddings = [[0, 0], [d, 0], [0, 0]]\n",
    "                    conv_padded = tf.pad(residual_flow, paddings, \"constant\")\n",
    "\n",
    "                    # Defining gated activation unit\n",
    "                    conv_gate = tf.sigmoid(tf.layers.conv1d(conv_padded, filters=n_dilation_filters,\n",
    "                                                            kernel_size=2, padding=\"valid\", \n",
    "                                                            name=\"dilated_block\" + str(block_num) + \"_\" + str(d) + \"_gate\", \n",
    "                                                            use_bias=False, dilation_rate=d\n",
    "                                                           )\n",
    "                                          )     \n",
    "\n",
    "                    # Defining filter for gated activation unit\n",
    "                    conv_filter = tf.tanh(tf.layers.conv1d(conv_padded, filters=n_dilation_filters,\n",
    "                                                           kernel_size=2, padding=\"valid\", \n",
    "                                                           name=\"dilated_block\" + str(block_num) + \"_\" + str(d) + \"_filter\", \n",
    "                                                           use_bias=False, dilation_rate=d\n",
    "                                                          )\n",
    "                                         ) \n",
    "\n",
    "                    # Calculating layer output to send via skip-connections \n",
    "                    # 1x1 convolutions are applied to squeeze several dilation filters (if present) \n",
    "                    conv_residual = tf.layers.conv1d(conv_filter * conv_gate, filters=n_residual_channels,\n",
    "                                                     kernel_size=1, strides=1, use_bias=False,\n",
    "                                                     name=\"dilated_block\" + str(block_num) + \"_\" + str(d) + \"_residual\"\n",
    "                                                    )\n",
    "\n",
    "                    # Necessary bookkeeping: updating residual_flow and connecting current output with final layers\n",
    "                    skip_connections_layer += conv_residual\n",
    "                    residual_flow += conv_residual\n",
    "                    \n",
    "            # Squashing residual channels for skip connections layer\n",
    "            trunc_skip_layer = tf.layers.conv1d(tf.nn.relu(skip_connections_layer), \n",
    "                                                filters=1, kernel_size=1, use_bias=False,\n",
    "                                                name=\"skip_connections_conv\")\n",
    "            \n",
    "            # Getting the base for quantizied signal probabilities\n",
    "            softmax_base = tf.layers.conv1d(tf.nn.relu(trunc_skip_layer), \n",
    "                                            filters=256, kernel_size=1, use_bias=False,\n",
    "                                            name=\"softmax_base\")\n",
    "                        \n",
    "            self.pred_proba = tf.nn.softmax(softmax_base)\n",
    "            \n",
    "            # Reminder: the WaveNet is a generative model so it is supposed to predict future signal values\n",
    "            # Thus I am comparing predicted probablilities against the original shifted input\n",
    "            loss_logits = softmax_base[:, :-1, :]\n",
    "            loss_labels = tf.one_hot(self.input_layer, depth=256, on_value=1, off_value=0)[:, 1:, :]\n",
    "            self.loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits=loss_logits, labels=loss_labels))\n",
    "            \n",
    "            self.adam = tf.train.AdamOptimizer(self.learning_rate).minimize(self.loss, var_list=self.model_variables())\n",
    "                    \n",
    "            self.session.run(tf.global_variables_initializer())\n",
    "\n",
    "    def model_variables(self):\n",
    "        return [x for x in tf.trainable_variables() if self.model_name in x.name]\n",
    "    \n",
    "    def model_size(self):\n",
    "        var_sizes = [tf.size(x) for x in self.model_variables()]\n",
    "        return self.session.run(tf.reduce_sum(var_sizes))\n",
    "    \n",
    "    def receptive_field(self):\n",
    "        return sum([2 ** i for i in range(self.max_dilation_base)]) * self.n_dilation_blocks\n",
    "    \n",
    "    def predict(self, track):\n",
    "        return self.session.run(self.pred_proba, feed_dict={self.input_layer: track})\n",
    "\n",
    "    def show_loss(self, track):\n",
    "        return self.session.run(self.loss, feed_dict={self.input_layer: track})\n",
    "    \n",
    "    def train_op(self, track):\n",
    "        self.session.run(self.adam, feed_dict={self.input_layer: track})\n",
    "        \n",
    "    def generate(self, track):\n",
    "        next_proba = self.session.run(self.pred_proba[:, -1, :], feed_dict={self.input_layer: track})\n",
    "        return np.random.choice(range(256), p=next_proba[0])        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing WaveNet implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "wv_model = WaveNet(\"wv_test\", \n",
    "                   n_dilation_blocks=4, \n",
    "                   max_dilation_base=8, \n",
    "                   n_dilation_filters=10, \n",
    "                   n_residual_channels=5)\n",
    "\n",
    "print(wv_model.model_size())\n",
    "print(wv_model.receptive_field())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "track = mu_law_encode(music_track[:1000].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    wv_model.train_op(track)\n",
    "    print(wv_model.show_loss(track))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continued_track = np.array(track)\n",
    "for i in range(1000):\n",
    "    if i % 100 == 0 or i < 10:\n",
    "        print(i)\n",
    "    next_signal = wv_model.generate(continued_track[:, -wv_model.receptive_field():])\n",
    "    continued_track = np.append(continued_track, np.array(next_signal).reshape(1, 1), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=music_track[:1000], rate=sample_rate, autoplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(data=mu_law_decode(continued_track), rate=sample_rate, autoplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(mu_law_decode(continued_track)[0])), mu_law_decode(continued_track)[0])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl_env]",
   "language": "python",
   "name": "conda-env-dl_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
