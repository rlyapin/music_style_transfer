{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default trying to load a mp3 file in the jupyter notebook may throw \"IOPub data rate exceeded\" exception.\n",
    "\n",
    "To avoid it restart the notebook with the following command: jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "from IPython.display import Audio\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.learn.python.learn.estimators import model_fn as model_fn_lib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the music track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MUSIC_TRACK, sample_rate = librosa.load(\"../../data/music/kalpol_introl.mp3\", mono=True)\n",
    "Audio(data=MUSIC_TRACK, rate=sample_rate, autoplay=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(MUSIC_TRACK)), MUSIC_TRACK)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying out dilated convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = tf.constant(list(range(10)), shape=[1, 10, 1], dtype=tf.float32)\n",
    "paddings = [[0, 0], [4, 0], [0, 0]]\n",
    "padded_sample = tf.pad(sample, paddings, \"constant\")\n",
    "conv_1d = tf.layers.conv1d(padded_sample, filters=3, kernel_size=2, padding=\"valid\", use_bias=False, dilation_rate=4) \n",
    "apply_1x1_conv = tf.layers.conv1d(conv_1d, filters=1, kernel_size=1, strides=1, use_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    out = conv_1d.eval()\n",
    "    out_1x1 = apply_1x1_conv.eval()\n",
    "    fil = tf.trainable_variables()[-1].eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_1x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing a block of dilated convolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dilation_steps = [2 ** i for i in range(10)]\n",
    "input_track = tf.constant(MUSIC_TRACK, shape=[1, len(MUSIC_TRACK), 1], dtype=tf.float32)\n",
    "\n",
    "last_layer = input_track\n",
    "for d in dilation_steps:\n",
    "    paddings = [[0, 0], [d, 0], [0, 0]]\n",
    "    padded_layer = tf.pad(last_layer, paddings, \"constant\")\n",
    "    next_layer = tf.layers.conv1d(padded_layer, filters=1, kernel_size=2, padding=\"valid\", \n",
    "                                  name=\"block1_\" + str(d), use_bias=False, dilation_rate=d)\n",
    "    last_layer = next_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_loss = tf.losses.mean_squared_error(last_layer[0, :-1, 0], input_track[0, 1:, 0])\n",
    "adam = tf.train.AdamOptimizer().minimize(mse_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(50):\n",
    "        current_mse_loss, _, last_filter = sess.run([mse_loss, adam, tf.trainable_variables()[-1]])\n",
    "        print(i, current_mse_loss, last_filter[:, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expressing WaveNet via TF Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model function for WaveNet Estimator\n",
    "\n",
    "So far the differences between this implementation and the one given in the paper: hardcoded single residual channel going throug the network and a simplified version of loss function (currently just mse loss between actual signal and predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_DILATION_SIZE_BASE_2 = 2\n",
    "N_DILATION_BLOCKS = 1\n",
    "N_DILATION_FILTERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fn(features, targets, mode, params):\n",
    "\n",
    "    # Setting the flow of residuals - will be additively accumulated through the network\n",
    "    # For the future: this to be replaced with additional 1x1 convolution if I go for N_RESIDUAL_CHANNELS > 1\n",
    "    residual_flow = features\n",
    "    \n",
    "    # Setting skip_connection_layer - it is going to accumulate all outputs of intermediary layers\n",
    "    # For the future: this has to point for current state of residual_flow if I go for N_RESIDUAL_CHANNELS > 1\n",
    "    skip_connections_layer = features\n",
    "    \n",
    "    # Going through stacks of dilated convolution layers\n",
    "    dilation_steps = [2 ** i for i in range(MAX_DILATION_SIZE_BASE_2)]\n",
    "    for block_num in range(1, N_DILATION_BLOCKS + 1):\n",
    "        for d in dilation_steps:\n",
    "            \n",
    "            # Padding the intermediary sequences / layers from left\n",
    "            paddings = [[0, 0], [d, 0], [0, 0]]\n",
    "            conv_padded = tf.pad(residual_flow, paddings, \"constant\")\n",
    "                        \n",
    "            # Defining gated activation unit\n",
    "            conv_gate = tf.sigmoid(tf.layers.conv1d(conv_padded, filters=N_DILATION_FILTERS, kernel_size=2, padding=\"valid\", \n",
    "                                                    name=\"dilated_block\" + str(block_num) + \"_\" + str(d) + \"_gate\", \n",
    "                                                    use_bias=False, dilation_rate=d\n",
    "                                                   )\n",
    "                                  )     \n",
    "\n",
    "            # Defining filter for gated activation unit\n",
    "            conv_filter = tf.tanh(tf.layers.conv1d(conv_padded, filters=N_DILATION_FILTERS, kernel_size=2, padding=\"valid\", \n",
    "                                                   name=\"dilated_block\" + str(block_num) + \"_\" + str(d) + \"_filter\", \n",
    "                                                   use_bias=False, dilation_rate=d\n",
    "                                                  )\n",
    "                                 ) \n",
    "            \n",
    "            # Calculating layer output to send via skip-connections \n",
    "            # 1x1 convolutions are applied to squeeze several dilation filters (if present) \n",
    "            # For the future: filters parameter is to be substituted with N_RESIDUAL_CHANNELS (if I introduce this parameter)\n",
    "            conv_residual = tf.layers.conv1d(conv_filter * conv_gate, filters=1, kernel_size=1, strides=1, use_bias=False,\n",
    "                                             name=\"dilated_block\" + str(block_num) + \"_\" + str(d) + \"_residual\"\n",
    "                                            )\n",
    "            \n",
    "            # Necessary bookkeeping: updating residual_flow and connecting current output with final layers\n",
    "            skip_connections_layer += conv_residual\n",
    "            residual_flow += conv_residual\n",
    "            \n",
    "    # The original paper takes accumulated skip_connection_layer and adds extra layers on top of it\n",
    "    # For simplicity current implementation stops here and takes mse between this layer and targets and a loss\n",
    "    predictions = skip_connections_layer\n",
    "    predictions_dict = {\"predicted_sample\": predictions}\n",
    "\n",
    "    # Calculate loss using mse between actual and predicted sample\n",
    "    # Note: as WaveNet is generative model - it tries to predict next signal so two tensors are shifted wrt each other\n",
    "    loss = tf.losses.mean_squared_error(tf.contrib.layers.flatten(targets)[1:], \n",
    "                                        tf.contrib.layers.flatten(predictions)[:-1])\n",
    "\n",
    "    # Defining optimization step: picking adam as main optimizer\n",
    "    # For simplicitly hardcoding parameters and not addressing params input\n",
    "    adam = tf.train.AdamOptimizer()\n",
    "    train_op = tf.contrib.layers.optimize_loss(loss=loss,\n",
    "                                               global_step=tf.contrib.framework.get_global_step(),\n",
    "                                               learning_rate=0.01,\n",
    "                                               optimizer=adam\n",
    "                                              )\n",
    "\n",
    "    return model_fn_lib.ModelFnOps(mode=mode,\n",
    "                                   predictions=predictions_dict,\n",
    "                                   loss=loss,\n",
    "                                   train_op=train_op\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wavenet = tf.contrib.learn.Estimator(model_fn=model_fn, params={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the future this functions should be replaced with generators\n",
    "# As WaveNet is generative model both x and y refer to the same piece of music:\n",
    "# Necessary relative shifting of x and y is done inside model_fn definition of loss function\n",
    "def get_inputs():\n",
    "    x = tf.constant(MUSIC_TRACK, shape=[1, len(MUSIC_TRACK), 1], dtype=tf.float32)\n",
    "    y = tf.constant(MUSIC_TRACK, shape=[1, len(MUSIC_TRACK), 1], dtype=tf.float32)\n",
    "    return x, y\n",
    "\n",
    "# Testing the fit method of WaveNet\n",
    "wavenet.fit(input_fn=get_inputs, steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the evaluate method of WaveNet\n",
    "ev = wavenet.evaluate(input_fn=get_inputs, steps=1)\n",
    "print(ev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing filter extraction\n",
    "test_filter = wavenet.get_variable_names()[-3]\n",
    "wavenet.get_variable_value(test_filter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl_env]",
   "language": "python",
   "name": "conda-env-dl_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
